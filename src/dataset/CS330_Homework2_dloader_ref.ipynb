{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS330_Homework2_EdwinPan_Submission.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvkoC8rAYBE7"
      },
      "source": [
        "\n",
        "##Model-Agnostic Meta-Learning and PrototypicalNetworks\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBkP5aBdfFkd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7132f7fb-d5fd-4257-f4fa-2e3c47e7b3d5"
      },
      "source": [
        "import os\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "\n",
        "# Need to download the Omniglot dataset -- DON'T MODIFY THIS CELL\n",
        "if not os.path.isdir('./omniglot_resized'):\n",
        "    gdd.download_file_from_google_drive(file_id='1iaSFXIYC3AB8q9K_M-oVMa4pmB7yKMtI',\n",
        "                                        dest_path='./omniglot_resized.zip',\n",
        "                                        unzip=True)\n",
        "else:\n",
        "    print(\"Data already downloaded\")\n",
        "\n",
        "assert os.path.isdir('./omniglot_resized')\n",
        "\n",
        "# with gradient.Tape as tape:\n",
        "#    ..."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 1iaSFXIYC3AB8q9K_M-oVMa4pmB7yKMtI into ./omniglot_resized.zip... Done.\n",
            "Unzipping...Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMtiYUiwI-1K"
      },
      "source": [
        "\"\"\" Utility functions. \"\"\"\n",
        "## NOTE: You do not need to modify this block but you will need to use it.\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import tensorflow as tf\n",
        "\n",
        "## Loss utilities\n",
        "def cross_entropy_loss(pred, label, k_shot):\n",
        "    return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=tf.stop_gradient(label)) / k_shot)\n",
        "\n",
        "def accuracy(labels, predictions):\n",
        "  return tf.reduce_mean(tf.cast(tf.equal(labels, predictions), dtype=tf.float32))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ud5HlpnMlvL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "333e5646-8577-4484-e55c-2e44607b68b5"
      },
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_dTnU8JwWWc"
      },
      "source": [
        "\"\"\"Convolutional layers used by MAML model.\"\"\"\n",
        "## NOTE: You do not need to modify this block but you will need to use it.\n",
        "seed = 123\n",
        "def conv_block(inp, cweight, bweight, bn, activation=tf.nn.relu, residual=False):\n",
        "  \"\"\" Perform, conv, batch norm, nonlinearity, and max pool \"\"\"\n",
        "  stride, no_stride = [1,2,2,1], [1,1,1,1]\n",
        "\n",
        "  conv_output = tf.nn.conv2d(input=inp, filters=cweight, strides=no_stride, padding='SAME') + bweight\n",
        "  normed = bn(conv_output)\n",
        "  normed = activation(normed)\n",
        "  return normed\n",
        "\n",
        "class ConvLayers(tf.keras.layers.Layer):\n",
        "  def __init__(self, channels, dim_hidden, dim_output, img_size):\n",
        "    super(ConvLayers, self).__init__()\n",
        "    self.channels = channels\n",
        "    self.dim_hidden = dim_hidden\n",
        "    self.dim_output = dim_output\n",
        "    self.img_size = img_size\n",
        "\n",
        "    weights = {}\n",
        "\n",
        "    dtype = tf.float32\n",
        "    weight_initializer =  tf.keras.initializers.GlorotUniform()\n",
        "    k = 3\n",
        "\n",
        "    weights['conv1'] = tf.Variable(weight_initializer(shape=[k, k, self.channels, self.dim_hidden]), name='conv1', dtype=dtype)\n",
        "    weights['b1'] = tf.Variable(tf.zeros([self.dim_hidden]), name='b1')\n",
        "    self.bn1 = tf.keras.layers.BatchNormalization(name='bn1')\n",
        "    weights['conv2'] = tf.Variable(weight_initializer(shape=[k, k, self.dim_hidden, self.dim_hidden]), name='conv2', dtype=dtype)\n",
        "    weights['b2'] = tf.Variable(tf.zeros([self.dim_hidden]), name='b2')\n",
        "    self.bn2 = tf.keras.layers.BatchNormalization(name='bn2')\n",
        "    weights['conv3'] = tf.Variable(weight_initializer(shape=[k, k, self.dim_hidden, self.dim_hidden]), name='conv3', dtype=dtype)\n",
        "    weights['b3'] = tf.Variable(tf.zeros([self.dim_hidden]), name='b3')\n",
        "    self.bn3 = tf.keras.layers.BatchNormalization(name='bn3')\n",
        "    weights['conv4'] = tf.Variable(weight_initializer([k, k, self.dim_hidden, self.dim_hidden]), name='conv4', dtype=dtype)\n",
        "    weights['b4'] = tf.Variable(tf.zeros([self.dim_hidden]), name='b4')\n",
        "    self.bn4 = tf.keras.layers.BatchNormalization(name='bn4')\n",
        "    weights['w5'] = tf.Variable(weight_initializer(shape=[self.dim_hidden, self.dim_output]), name='w5', dtype=dtype)\n",
        "    weights['b5'] = tf.Variable(tf.zeros([self.dim_output]), name='b5')\n",
        "    self.conv_weights = weights\n",
        "\n",
        "  def call(self, inp, weights):\n",
        "    channels = self.channels\n",
        "    inp = tf.reshape(inp, [-1, self.img_size, self.img_size, channels])\n",
        "    hidden1 = conv_block(inp, weights['conv1'], weights['b1'], self.bn1)\n",
        "    hidden2 = conv_block(hidden1, weights['conv2'], weights['b2'], self.bn2)\n",
        "    hidden3 = conv_block(hidden2, weights['conv3'], weights['b3'], self.bn3)\n",
        "    hidden4 = conv_block(hidden3, weights['conv4'], weights['b4'], self.bn4)\n",
        "    hidden4 = tf.reduce_mean(input_tensor=hidden4, axis=[1, 2])\n",
        "    return tf.matmul(hidden4, weights['w5']) + weights['b5']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXZS_JULriBh"
      },
      "source": [
        "\"\"\"Data loading scripts\"\"\"\n",
        "## NOTE: You do not need to modify this block but you will need to use it.\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from scipy import misc\n",
        "import imageio\n",
        "\n",
        "def get_images(paths, labels, n_samples=None, shuffle=True):\n",
        "  \"\"\"\n",
        "  Takes a set of character folders and labels and returns paths to image files\n",
        "  paired with labels.\n",
        "  Args:\n",
        "    paths: A list of character folders\n",
        "    labels: List or numpy array of same length as paths\n",
        "    n_samples: Number of images to retrieve per character\n",
        "  Returns:\n",
        "    List of (label, image_path) tuples\n",
        "  \"\"\"\n",
        "  if n_samples is not None:\n",
        "    sampler = lambda x: random.sample(x, n_samples)\n",
        "  else:\n",
        "    sampler = lambda x: x\n",
        "  images_labels = [(i, os.path.join(path, image))\n",
        "           for i, path in zip(labels, paths)\n",
        "           for image in sampler(os.listdir(path))]\n",
        "  if shuffle:\n",
        "    random.shuffle(images_labels)\n",
        "  return images_labels\n",
        "\n",
        "\n",
        "def image_file_to_array(filename, dim_input):\n",
        "  \"\"\"\n",
        "  Takes an image path and returns numpy array\n",
        "  Args:\n",
        "    filename: Image filename\n",
        "    dim_input: Flattened shape of image\n",
        "  Returns:\n",
        "    1 channel image\n",
        "  \"\"\"\n",
        "  image = imageio.imread(filename)\n",
        "  image = image.reshape([dim_input])\n",
        "  image = image.astype(np.float32) / 255.0\n",
        "  image = 1.0 - image\n",
        "  return image\n",
        "  \n",
        "\n",
        "class DataGenerator(object):\n",
        "  \"\"\"\n",
        "  Data Generator capable of generating batches of Omniglot data.\n",
        "  A \"class\" is considered a class of omniglot digits.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, num_classes, num_samples_per_class, num_meta_test_classes, num_meta_test_samples_per_class, config={}):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      num_classes: Number of classes for classification (K-way)\n",
        "      num_samples_per_class: num samples to generate per class in one batch\n",
        "      num_meta_test_classes: Number of classes for classification (K-way) at meta-test time\n",
        "      num_meta_test_samples_per_class: num samples to generate per class in one batch at meta-test time\n",
        "      batch_size: size of meta batch size (e.g. number of functions)\n",
        "    \"\"\"\n",
        "    self.num_samples_per_class = num_samples_per_class\n",
        "    self.num_classes = num_classes\n",
        "    self.num_meta_test_samples_per_class = num_meta_test_samples_per_class\n",
        "    self.num_meta_test_classes = num_meta_test_classes\n",
        "\n",
        "    data_folder = config.get('data_folder', './omniglot_resized')\n",
        "    self.img_size = config.get('img_size', (28, 28))\n",
        "\n",
        "    self.dim_input = np.prod(self.img_size)\n",
        "    self.dim_output = self.num_classes\n",
        "\n",
        "    character_folders = [os.path.join(data_folder, family, character)\n",
        "               for family in os.listdir(data_folder)\n",
        "               if os.path.isdir(os.path.join(data_folder, family))\n",
        "               for character in os.listdir(os.path.join(data_folder, family))\n",
        "               if os.path.isdir(os.path.join(data_folder, family, character))]\n",
        "\n",
        "    random.seed(123)\n",
        "    random.shuffle(character_folders)\n",
        "    num_val = 100\n",
        "    num_train = 1100\n",
        "    self.metatrain_character_folders = character_folders[: num_train]\n",
        "    self.metaval_character_folders = character_folders[\n",
        "      num_train:num_train + num_val]\n",
        "    self.metatest_character_folders = character_folders[\n",
        "      num_train + num_val:]\n",
        "\n",
        "  def sample_batch(self, batch_type, batch_size, shuffle=True, swap=False):\n",
        "    \"\"\"\n",
        "    Samples a batch for training, validation, or testing\n",
        "    Args:\n",
        "      batch_type: meta_train/meta_val/meta_test\n",
        "      shuffle: randomly shuffle classes or not\n",
        "      swap: swap number of classes (N) and number of samples per class (K) or not\n",
        "    Returns:\n",
        "      A a tuple of (1) Image batch and (2) Label batch where\n",
        "      image batch has shape [B, N, K, 784] and label batch has shape [B, N, K, N] if swap is False\n",
        "      where B is batch size, K is number of samples per class, N is number of classes\n",
        "    \"\"\"\n",
        "    if batch_type == \"meta_train\":\n",
        "      folders = self.metatrain_character_folders\n",
        "      num_classes = self.num_classes\n",
        "      num_samples_per_class = self.num_samples_per_class\n",
        "    elif batch_type == \"meta_val\":\n",
        "      folders = self.metaval_character_folders\n",
        "      num_classes = self.num_classes\n",
        "      num_samples_per_class = self.num_samples_per_class\n",
        "    else:\n",
        "      folders = self.metatest_character_folders\n",
        "      num_classes = self.num_meta_test_classes\n",
        "      num_samples_per_class = self.num_meta_test_samples_per_class\n",
        "    all_image_batches, all_label_batches = [], []\n",
        "    for i in range(batch_size):\n",
        "      sampled_character_folders = random.sample(\n",
        "        folders, num_classes)\n",
        "      labels_and_images = get_images(sampled_character_folders, range(\n",
        "        num_classes), n_samples=num_samples_per_class, shuffle=False)\n",
        "      labels = [li[0] for li in labels_and_images]\n",
        "      images = [image_file_to_array(\n",
        "        li[1], self.dim_input) for li in labels_and_images]\n",
        "      images = np.stack(images)\n",
        "      labels = np.array(labels).astype(np.int32)\n",
        "      labels = np.reshape(\n",
        "        labels, (num_classes, num_samples_per_class))\n",
        "      labels = np.eye(num_classes, dtype=np.float32)[labels]\n",
        "      images = np.reshape(\n",
        "        images, (num_classes, num_samples_per_class, -1))\n",
        "\n",
        "      batch = np.concatenate([labels, images], 2)\n",
        "      if shuffle:\n",
        "        for p in range(num_samples_per_class):\n",
        "          np.random.shuffle(batch[:, p])\n",
        "\n",
        "      labels = batch[:, :, :num_classes]\n",
        "      images = batch[:, :, num_classes:]\n",
        "\n",
        "      if swap:\n",
        "        labels = np.swapaxes(labels, 0, 1)\n",
        "        images = np.swapaxes(images, 0, 1)\n",
        "\n",
        "      all_image_batches.append(images)\n",
        "      all_label_batches.append(labels)\n",
        "    all_image_batches = np.stack(all_image_batches)\n",
        "    all_label_batches = np.stack(all_label_batches)\n",
        "    return all_image_batches, all_label_batches"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxriXFvwsGfp"
      },
      "source": [
        "\"\"\"MAML model code\"\"\"\n",
        "import numpy as np\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "from functools import partial\n",
        "\n",
        "\n",
        "class MAML(tf.keras.Model):\n",
        "  def __init__(self, dim_input=1, dim_output=1,\n",
        "               num_inner_updates=1,\n",
        "               inner_update_lr=0.4, num_filters=32, k_shot=5, learn_inner_update_lr=False):\n",
        "    super(MAML, self).__init__()\n",
        "    self.dim_input = dim_input\n",
        "    self.dim_output = dim_output\n",
        "    self.inner_update_lr = inner_update_lr\n",
        "    self.loss_func = partial(cross_entropy_loss, k_shot=1)\n",
        "    self.dim_hidden = num_filters\n",
        "    self.channels = 1\n",
        "    self.img_size = int(np.sqrt(self.dim_input/self.channels))\n",
        "\n",
        "    # outputs_ts[i] and losses_ts_post[i] are the output and loss after i+1 inner gradient updates\n",
        "    losses_tr_pre, outputs_tr, losses_ts_post, outputs_ts = [], [], [], []\n",
        "    accuracies_tr_pre, accuracies_ts = [], []\n",
        "\n",
        "    # for each loop in the inner training loop\n",
        "    outputs_ts = [[]]*num_inner_updates\n",
        "    losses_ts_post = [[]]*num_inner_updates\n",
        "    accuracies_ts = [[]]*num_inner_updates\n",
        "\n",
        "    # Define the weights - these should NOT be directly modified by the\n",
        "    # inner training loop\n",
        "    tf.random.set_seed(seed)\n",
        "    self.conv_layers = ConvLayers(self.channels, self.dim_hidden, self.dim_output, self.img_size)\n",
        "\n",
        "    self.learn_inner_update_lr = learn_inner_update_lr\n",
        "    if self.learn_inner_update_lr:\n",
        "      self.inner_update_lr_dict = {}\n",
        "      for key in self.conv_layers.conv_weights.keys():\n",
        "        self.inner_update_lr_dict[key] = [tf.Variable(self.inner_update_lr, name='inner_update_lr_%s_%d' % (key, j)) for j in range(num_inner_updates)]\n",
        "  \n",
        "\n",
        "  def call(self, inp, meta_batch_size=25, num_inner_updates=1):\n",
        "    def task_inner_loop(inp, reuse=True,\n",
        "                      meta_batch_size=25, num_inner_updates=1):\n",
        "      \"\"\"\n",
        "        Perform gradient descent for one task in the meta-batch (i.e. inner-loop).\n",
        "        Args:\n",
        "          inp: a tuple (input_tr, input_ts, label_tr, label_ts), where input_tr and label_tr are the inputs and\n",
        "            labels used for calculating inner loop gradients and input_ts and label_ts are the inputs and\n",
        "            labels used for evaluating the model after inner updates.\n",
        "            Should be shapes:\n",
        "              input_tr: [N*K, 784]\n",
        "              input_ts: [N*K, 784]\n",
        "              label_tr: [N*K, N]\n",
        "              label_ts: [N*K, N]\n",
        "        Returns:\n",
        "          task_output: a list of outputs, losses and accuracies at each inner update\n",
        "      \"\"\"\n",
        "      # the inner and outer loop data\n",
        "      input_tr, input_ts, label_tr, label_ts = inp\n",
        "\n",
        "      # weights corresponds to the initial weights in MAML (i.e. the meta-parameters)\n",
        "      weights = self.conv_layers.conv_weights\n",
        "\n",
        "      # the predicted outputs, loss values, and accuracy for the pre-update model (with the initial weights)\n",
        "      # evaluated on the inner loop training data\n",
        "      task_output_tr_pre, task_loss_tr_pre, task_accuracy_tr_pre = None, None, None\n",
        "\n",
        "      # lists to keep track of outputs, losses, and accuracies of test data for each inner_update\n",
        "      # where task_outputs_ts[i], task_losses_ts[i], task_accuracies_ts[i] are the output, loss, and accuracy\n",
        "      # after i+1 inner gradient updates\n",
        "      task_outputs_ts, task_losses_ts, task_accuracies_ts = [], [], []\n",
        "  \n",
        "      #############################\n",
        "      #### YOUR CODE GOES HERE ####\n",
        "      # perform num_inner_updates to get modified weights\n",
        "      # modified weights should be used to evaluate performance\n",
        "      # Note that at each inner update, always use input_tr and label_tr for calculating gradients\n",
        "      # and use input_ts and labels for evaluating performance\n",
        "\n",
        "      # HINTS: You will need to use tf.GradientTape().\n",
        "      # Read through the tf.GradientTape() documentation to see how 'persistent' should be set.\n",
        "      # Here is some documentation that may be useful: \n",
        "      # https://www.tensorflow.org/guide/advanced_autodiff#higher-order_gradients\n",
        "      # https://www.tensorflow.org/api_docs/python/tf/GradientTape\n",
        "\n",
        "      # -------------------- Utility --------------------\n",
        "      # Store a copy of the weights for inner-loop\n",
        "      # inner_task_weights = dict(zip(weights.keys(), [weights[key] for key in weights.keys()]))\n",
        "\n",
        "      # # Set the optimizer used for updating gradients\n",
        "      # if not self.learn_inner_update_lr:\n",
        "      #   optimizer = tf.keras.optimizers.SGD(learning_rate=self.inner_update_lr)\n",
        "      # else:\n",
        "      #   optimizer = tf.keras.optimizers.SGD(learning_rate=self.inner_update_lr)\n",
        "      #   print(\"IMPLEMENT ME! [Part 4]\")\n",
        "\n",
        "      # -------------------- First Iter --------------------\n",
        "      with tf.GradientTape(persistent=True) as inner_tape:\n",
        "        # Compute prediction based on current weights\n",
        "        task_output_tr_pre = self.conv_layers(input_tr, weights)\n",
        "        # Compute inner-loop loss based on prediction\n",
        "        task_loss_tr_pre = self.loss_func(task_output_tr_pre, label_tr)\n",
        "        # print(\"[ITER \", str(0), \"] DEBUG INNER-LOOP LOSS: \", task_loss_tr_pre)\n",
        "\n",
        "      # Apply gradient w.r.t \\theta on the current loss\n",
        "      gradients = inner_tape.gradient(task_loss_tr_pre, weights)\n",
        "      if self.learn_inner_update_lr:\n",
        "        inner_task_weights = dict(zip(weights.keys(), [weights[key] - self.inner_update_lr_dict[key]*gradients[key] for key in weights.keys()]))\n",
        "      else:\n",
        "        inner_task_weights = dict(zip(weights.keys(), [weights[key] - self.inner_update_lr*gradients[key] for key in weights.keys()]))\n",
        "\n",
        "      # Test new weights on test data and record results\n",
        "      task_outputs_ts.append(self.conv_layers(input_ts, inner_task_weights))\n",
        "      task_losses_ts.append(self.loss_func(task_outputs_ts[-1], label_ts))\n",
        "\n",
        "\n",
        "      # -------------------- Other Iters --------------------\n",
        "      for j in range(num_inner_updates-1):\n",
        "        with tf.GradientTape(persistent=True) as inner_tape:\n",
        "          # Compute prediction based on current weights\n",
        "          pred = self.conv_layers(input_tr, inner_task_weights)\n",
        "          # Compute inner-loop loss based on prediction\n",
        "          curr_loss = self.loss_func(pred, label_tr)\n",
        "          # print(\"[ITER \", j+1, \"] DEBUG INNER-LOOP LOSS: \", curr_loss)\n",
        "\n",
        "        # Apply gradient w.r.t \\theta on the current loss\n",
        "        gradients = inner_tape.gradient(curr_loss, inner_task_weights)\n",
        "        if self.learn_inner_update_lr:\n",
        "          inner_task_weights = dict(zip(weights.keys(), [weights[key] - self.inner_update_lr_dict[key]*gradients[key] for key in weights.keys()]))\n",
        "        else:\n",
        "          inner_task_weights = dict(zip(inner_task_weights.keys(), [inner_task_weights[key] - self.inner_update_lr*gradients[key] for key in inner_task_weights.keys()]))\n",
        "\n",
        "        # Test new weights on test data and record results\n",
        "        task_outputs_ts.append(self.conv_layers(input_ts, inner_task_weights))\n",
        "        task_losses_ts.append(self.loss_func(task_outputs_ts[-1], label_ts))\n",
        "\n",
        "      #############################\n",
        "\n",
        "      # Compute accuracies from output predictions\n",
        "      task_accuracy_tr_pre = accuracy(tf.argmax(input=label_tr, axis=1), tf.argmax(input=tf.nn.softmax(task_output_tr_pre), axis=1))\n",
        "\n",
        "      for j in range(num_inner_updates):\n",
        "        task_accuracies_ts.append(accuracy(tf.argmax(input=label_ts, axis=1), tf.argmax(input=tf.nn.softmax(task_outputs_ts[j]), axis=1)))\n",
        "\n",
        "      task_output = [task_output_tr_pre, task_outputs_ts, task_loss_tr_pre, task_losses_ts, task_accuracy_tr_pre, task_accuracies_ts]\n",
        "\n",
        "      return task_output\n",
        "\n",
        "    input_tr, input_ts, label_tr, label_ts = inp\n",
        "    # to initialize the batch norm vars, might want to combine this, and not run idx 0 twice.\n",
        "    unused = task_inner_loop((input_tr[0], input_ts[0], label_tr[0], label_ts[0]),\n",
        "                          False,\n",
        "                          meta_batch_size,\n",
        "                          num_inner_updates)\n",
        "    out_dtype = [tf.float32, [tf.float32]*num_inner_updates, tf.float32, [tf.float32]*num_inner_updates]\n",
        "    out_dtype.extend([tf.float32, [tf.float32]*num_inner_updates])\n",
        "    task_inner_loop_partial = partial(task_inner_loop, meta_batch_size=meta_batch_size, num_inner_updates=num_inner_updates)\n",
        "\n",
        "    result = tf.map_fn(task_inner_loop_partial,\n",
        "                    elems=(input_tr, input_ts, label_tr, label_ts),\n",
        "                    dtype=out_dtype,\n",
        "                    parallel_iterations=meta_batch_size)\n",
        "    return result\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v66zOMU-bXcA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6c268623-758b-4d72-ee57-37a7ecda8298"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xy1pz_ousUsz"
      },
      "source": [
        "\"\"\"Model training code\"\"\"\n",
        "\"\"\"\n",
        "Usage Instructions:\n",
        "  5-way, 1-shot omniglot:\n",
        "    python main.py --meta_train_iterations=15000 --meta_batch_size=25 --k_shot=1 --inner_update_lr=0.4 --num_inner_updates=1 --logdir=logs/omniglot5way/\n",
        "  20-way, 1-shot omniglot:\n",
        "    python main.py --meta_train_iterations=15000 --meta_batch_size=16 --k_shot=1 --n_way=20 --inner_update_lr=0.1 --num_inner_updates=5 --logdir=logs/omniglot20way/\n",
        "  To run evaluation, use the '--meta_train=False' flag and the '--meta_test_set=True' flag to use the meta-test set.\n",
        "\"\"\"\n",
        "import csv\n",
        "import numpy as np\n",
        "import pickle\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def outer_train_step(inp, model, optim, meta_batch_size=25, num_inner_updates=1):\n",
        "  with tf.GradientTape(persistent=False) as outer_tape:\n",
        "    result = model(inp, meta_batch_size=meta_batch_size, num_inner_updates=num_inner_updates)\n",
        "\n",
        "    outputs_tr, outputs_ts, losses_tr_pre, losses_ts, accuracies_tr_pre, accuracies_ts = result\n",
        "\n",
        "    total_losses_ts = [tf.reduce_mean(loss_ts) for loss_ts in losses_ts]\n",
        "\n",
        "  gradients = outer_tape.gradient(total_losses_ts[-1], model.trainable_variables)\n",
        "  optim.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "  total_loss_tr_pre = tf.reduce_mean(losses_tr_pre)\n",
        "  total_accuracy_tr_pre = tf.reduce_mean(accuracies_tr_pre)\n",
        "  total_accuracies_ts = [tf.reduce_mean(accuracy_ts) for accuracy_ts in accuracies_ts]\n",
        "\n",
        "  return outputs_tr, outputs_ts, total_loss_tr_pre, total_losses_ts, total_accuracy_tr_pre, total_accuracies_ts\n",
        "\n",
        "def outer_eval_step(inp, model, meta_batch_size=25, num_inner_updates=1):\n",
        "  result = model(inp, meta_batch_size=meta_batch_size, num_inner_updates=num_inner_updates)\n",
        "\n",
        "  outputs_tr, outputs_ts, losses_tr_pre, losses_ts, accuracies_tr_pre, accuracies_ts = result\n",
        "\n",
        "  total_loss_tr_pre = tf.reduce_mean(losses_tr_pre)\n",
        "  total_losses_ts = [tf.reduce_mean(loss_ts) for loss_ts in losses_ts]\n",
        "\n",
        "  total_accuracy_tr_pre = tf.reduce_mean(accuracies_tr_pre)\n",
        "  total_accuracies_ts = [tf.reduce_mean(accuracy_ts) for accuracy_ts in accuracies_ts]\n",
        "\n",
        "  return outputs_tr, outputs_ts, total_loss_tr_pre, total_losses_ts, total_accuracy_tr_pre, total_accuracies_ts  \n",
        "\n",
        "\n",
        "def meta_train_fn(model, exp_string, data_generator,\n",
        "               n_way=5, meta_train_iterations=15000, meta_batch_size=25,\n",
        "               log=True, logdir='/tmp/data', k_shot=1, num_inner_updates=1, meta_lr=0.001):\n",
        "  SUMMARY_INTERVAL = 10\n",
        "  SAVE_INTERVAL = 100\n",
        "  PRINT_INTERVAL = 10  \n",
        "  TEST_PRINT_INTERVAL = PRINT_INTERVAL*5\n",
        "\n",
        "  print(\"-------------------- Classification Stats --------------------\")\n",
        "  print(\"n_way=\", n_way)\n",
        "  print(\"k_shot=\", k_shot)\n",
        "  print(\"-------------------- Classification Stats --------------------\")\n",
        "  pre_accuracies, post_accuracies = [], []\n",
        "\n",
        "  num_classes = data_generator.num_classes\n",
        "\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=meta_lr)\n",
        "\n",
        "  meta_val_pre_accuracies_log = []\n",
        "  meta_val_post_accuracies_log = []\n",
        "  meta_val_iteration_key = []\n",
        "\n",
        "  F_meta_val_pre_accuracies_log = open(\"drive/My Drive/meta_val_pre_accuracies_log.txt\",\"w\")\n",
        "  F_meta_val_post_accuracies_log = open(\"drive/My Drive/meta_val_post_accuracies_log.txt\",\"w\")\n",
        "  F_meta_val_iteration_key = open(\"drive/My Drive/meta_val_iteration_key.txt\",\"w\")\n",
        "\n",
        "  for itr in range(meta_train_iterations):\n",
        "    #############################\n",
        "    #### YOUR CODE GOES HERE ####\n",
        "\n",
        "    # sample a batch of training data and partition into\n",
        "    # group a (input_tr, label_tr) and group b (input_ts, label_ts)\n",
        "    # ---------------------------\n",
        "    # EP: Start Implementation\n",
        "    inputs, labels = data_generator.sample_batch('meta_train', meta_batch_size)\n",
        "    # EP: Group A\n",
        "    input_tr = inputs[:,:,0,:] \n",
        "    label_tr = labels[:,:,0,:] \n",
        "\n",
        "    # EP: Group B\n",
        "    input_ts = inputs[:,:,1,:] \n",
        "    label_ts = labels[:,:,1,:] \n",
        "\n",
        "    #############################\n",
        "\n",
        "    inp = (input_tr, input_ts, label_tr, label_ts)\n",
        "    \n",
        "    result = outer_train_step(inp, model, optimizer, meta_batch_size=meta_batch_size, num_inner_updates=num_inner_updates)\n",
        "\n",
        "    if itr % SUMMARY_INTERVAL == 0:\n",
        "      pre_accuracies.append(result[-2])\n",
        "      post_accuracies.append(result[-1][-1])\n",
        "\n",
        "    if (itr!=0) and itr % PRINT_INTERVAL == 0:\n",
        "      print_str = 'Iteration %d: pre-inner-loop train accuracy: %.5f, post-inner-loop test accuracy: %.5f' % (itr, np.mean(pre_accuracies), np.mean(post_accuracies))\n",
        "      print(print_str)\n",
        "      pre_accuracies, post_accuracies = [], []\n",
        "\n",
        "    if (itr!=0) and itr % TEST_PRINT_INTERVAL == 0:\n",
        "      #############################\n",
        "      #### YOUR CODE GOES HERE ####\n",
        "\n",
        "      # sample a batch of validation data and partition into\n",
        "      # training (input_tr, label_tr) and testing (input_ts, label_ts)\n",
        "      # ---------------------------\n",
        "      # EP: Start Implementation\n",
        "      inputs, labels = data_generator.sample_batch('meta_val', meta_batch_size)\n",
        "      # EP: Group A\n",
        "      input_tr = inputs[:,:,0,:] \n",
        "      label_tr = labels[:,:,0,:] \n",
        "\n",
        "      # EP: Group B\n",
        "      input_ts = inputs[:,:,1,:] \n",
        "      label_ts = labels[:,:,1,:] \n",
        "      #############################\n",
        "\n",
        "      inp = (input_tr, input_ts, label_tr, label_ts)\n",
        "      result = outer_eval_step(inp, model, meta_batch_size=meta_batch_size, num_inner_updates=num_inner_updates)\n",
        "\n",
        "      meta_val_pre_accuracies_log.append(result[-2])\n",
        "      meta_val_post_accuracies_log.append(result[-1][-1])\n",
        "      meta_val_iteration_key.append(itr)\n",
        "\n",
        "      F_meta_val_pre_accuracies_log.write(str(result[-2])+ '\\n')\n",
        "      F_meta_val_post_accuracies_log.write(str(result[-1][-1])+ '\\n')\n",
        "      F_meta_val_iteration_key.write(str(itr)+ '\\n')\n",
        "\n",
        "      print('Meta-validation pre-inner-loop train accuracy: %.5f, meta-validation post-inner-loop test accuracy: %.5f' % (result[-2], result[-1][-1]))\n",
        "\n",
        "  # Plot Results\n",
        "  plt.figure(figsize=(12,8))\n",
        "  plt.plot(meta_val_iteration_key, meta_val_pre_accuracies_log, label=\"pre-acc\")\n",
        "  plt.plot(meta_val_iteration_key, meta_val_post_accuracies_log, label=\"post-acc\")\n",
        "  plt.title(\"Meta-val results for lr=\"+str(model.inner_update_lr))\n",
        "  plt.xlabel(\"Iterations\")\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.ylim([0,1])\n",
        "  plt.grid()\n",
        "  plt.legend()\n",
        "\n",
        "  F_meta_val_pre_accuracies_log.close()\n",
        "  F_meta_val_post_accuracies_log.close()\n",
        "  F_meta_val_iteration_key.close()\n",
        "\n",
        "  # Save Results\n",
        "  np.save(\"drive/My Drive/meta_val_pre_accuracies_log.npy\", np.array(meta_val_pre_accuracies_log))\n",
        "  np.save(\"drive/My Drive/meta_val_post_accuracies_log.npy\", np.array(meta_val_post_accuracies_log))\n",
        "  np.save(\"drive/My Drive/meta_val_iteration_key.npy\", np.array(meta_val_iteration_key))\n",
        "\n",
        "  model_file = logdir + '/' + exp_string +  '/model' + str(itr)\n",
        "  print(\"Saving to \", model_file)\n",
        "  model.save_weights(model_file)\n",
        "\n",
        "# calculated for omniglot\n",
        "NUM_META_TEST_POINTS = 600\n",
        "\n",
        "def meta_test_fn(model, data_generator, n_way=5, meta_batch_size=25, k_shot=1,\n",
        "              num_inner_updates=1):\n",
        "  \n",
        "  num_classes = data_generator.num_classes\n",
        "\n",
        "  np.random.seed(1)\n",
        "  random.seed(1)\n",
        "\n",
        "  meta_test_accuracies = []\n",
        "\n",
        "  for _ in range(NUM_META_TEST_POINTS):\n",
        "    #############################\n",
        "    #### YOUR CODE GOES HERE ####\n",
        "\n",
        "    # sample a batch of test data and partition into\n",
        "    # group a (input_tr, label_tr) and group b (input_ts, label_ts)\n",
        "    # EP: Start Implementation\n",
        "    inputs, labels = data_generator.sample_batch('meta_test', meta_batch_size)\n",
        "    # EP: Group A\n",
        "    input_tr = inputs[:,:,0,:] \n",
        "    label_tr = labels[:,:,0,:] \n",
        "\n",
        "    # EP: Group B\n",
        "    input_ts = inputs[:,:,1,:]\n",
        "    label_ts = labels[:,:,1,:] \n",
        "    #############################\n",
        "    inp = (input_tr, input_ts, label_tr, label_ts)\n",
        "    result = outer_eval_step(inp, model, meta_batch_size=meta_batch_size, num_inner_updates=num_inner_updates)\n",
        "\n",
        "    meta_test_accuracies.append(result[-1][-1])\n",
        "\n",
        "  meta_test_accuracies = np.array(meta_test_accuracies)\n",
        "  means = np.mean(meta_test_accuracies)\n",
        "  stds = np.std(meta_test_accuracies)\n",
        "  ci95 = 1.96*stds/np.sqrt(NUM_META_TEST_POINTS)\n",
        "\n",
        "  print('Mean meta-test accuracy/loss, stddev, and confidence intervals')\n",
        "  print((means, stds, ci95))\n",
        "\n",
        "\n",
        "def run_maml(n_way=5, k_shot=1, meta_batch_size=25, meta_lr=0.001,\n",
        "             inner_update_lr=0.4, num_filters=32, num_inner_updates=1,\n",
        "             learn_inner_update_lr=False,\n",
        "             resume=False, resume_itr=0, log=True, logdir='/tmp/data',\n",
        "             data_path='./omniglot_resized',meta_train=True,\n",
        "             meta_train_iterations=15000, meta_train_k_shot=-1,\n",
        "             meta_train_inner_update_lr=-1):\n",
        "\n",
        "\n",
        "  # call data_generator and get data with k_shot*2 samples per class\n",
        "  data_generator = DataGenerator(n_way, k_shot*2, n_way, k_shot*2, config={'data_folder': data_path})\n",
        "\n",
        "  # set up MAML model\n",
        "  dim_output = data_generator.dim_output\n",
        "  dim_input = data_generator.dim_input\n",
        "  model = MAML(dim_input,\n",
        "              dim_output,\n",
        "              num_inner_updates=num_inner_updates,\n",
        "              inner_update_lr=inner_update_lr,\n",
        "              k_shot=k_shot,\n",
        "              num_filters=num_filters,\n",
        "              learn_inner_update_lr=learn_inner_update_lr)\n",
        "\n",
        "  if meta_train_k_shot == -1:\n",
        "    meta_train_k_shot = k_shot\n",
        "  if meta_train_inner_update_lr == -1:\n",
        "    meta_train_inner_update_lr = inner_update_lr\n",
        "\n",
        "  exp_string = 'cls_'+str(n_way)+'.mbs_'+str(meta_batch_size) + '.k_shot_' + str(meta_train_k_shot) + '.inner_numstep_' + str(num_inner_updates) + '.inner_updatelr_' + str(meta_train_inner_update_lr) + '.learn_inner_update_lr_' + str(learn_inner_update_lr)\n",
        "\n",
        "\n",
        "  if meta_train:\n",
        "    meta_train_fn(model, exp_string, data_generator,\n",
        "                  n_way, meta_train_iterations, meta_batch_size, log, logdir,\n",
        "                  k_shot, num_inner_updates, meta_lr)\n",
        "  else:\n",
        "    meta_batch_size = 1\n",
        "\n",
        "    model_file = tf.train.latest_checkpoint(logdir + '/' + exp_string)\n",
        "    print(\"Restoring model weights from \", model_file)\n",
        "    model.load_weights(model_file)\n",
        "\n",
        "    meta_test_fn(model, data_generator, n_way, meta_batch_size, k_shot, num_inner_updates)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USOh7VulTMK3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "48f1d126-1b22-4ee0-f0bb-8d29d1159b11"
      },
      "source": [
        "run_maml(n_way=5, k_shot=1, inner_update_lr=4.0, num_inner_updates=1, learn_inner_update_lr=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cls_5.mbs_25.k_shot_1.inner_numstep_1.inner_updatelr_4.0.learn_inner_update_lr_True\n",
            "-------------------- Classification Stats --------------------\n",
            "n_way= 5\n",
            "k_shot= 1\n",
            "-------------------- Classification Stats --------------------\n",
            "WARNING:tensorflow:Setting parallel_iterations > 1 has no effect when executing eagerly. Consider calling map_fn with tf.function to execute fn in parallel.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-7792f72ed814>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_maml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_way\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_update_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_inner_updates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn_inner_update_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-52-55e1170792ae>\u001b[0m in \u001b[0;36mrun_maml\u001b[0;34m(n_way, k_shot, meta_batch_size, meta_lr, inner_update_lr, num_filters, num_inner_updates, learn_inner_update_lr, resume, resume_itr, log, logdir, data_path, meta_train, meta_train_iterations, meta_train_k_shot, meta_train_inner_update_lr)\u001b[0m\n\u001b[1;32m    236\u001b[0m     meta_train_fn(model, exp_string, data_generator,\n\u001b[1;32m    237\u001b[0m                   \u001b[0mn_way\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_train_iterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m                   k_shot, num_inner_updates, meta_lr)\n\u001b[0m\u001b[1;32m    239\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0mmeta_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-52-55e1170792ae>\u001b[0m in \u001b[0;36mmeta_train_fn\u001b[0;34m(model, exp_string, data_generator, n_way, meta_train_iterations, meta_batch_size, log, logdir, k_shot, num_inner_updates, meta_lr)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_ts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mouter_train_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeta_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_inner_updates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_inner_updates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mitr\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mSUMMARY_INTERVAL\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-52-55e1170792ae>\u001b[0m in \u001b[0;36mouter_train_step\u001b[0;34m(inp, model, optim, meta_batch_size, num_inner_updates)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mtotal_losses_ts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_ts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mloss_ts\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlosses_ts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m   \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mouter_tape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_losses_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m   \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1071\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1073\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    160\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_grad.py\u001b[0m in \u001b[0;36m_ReshapeGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    756\u001b[0m   return [\n\u001b[1;32m    757\u001b[0m       array_ops.reshape(\n\u001b[0;32m--> 758\u001b[0;31m           _IndexedSlicesToTensorNoWarning(grad), array_ops.shape(op.inputs[0])),\n\u001b[0m\u001b[1;32m    759\u001b[0m       \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m   ]\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mHas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m   \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m   \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_set_static_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m   8214\u001b[0m   \"\"\"\n\u001b[1;32m   8215\u001b[0m   \u001b[0m_ctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8216\u001b[0;31m   \u001b[0mtld\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8217\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8218\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPHRmeoIw8au"
      },
      "source": [
        "run_maml(n_way=5, k_shot=1, inner_update_lr=4.0, num_inner_updates=1, learn_inner_update_lr=True, meta_train=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSKXy7gO9f0U"
      },
      "source": [
        "run_maml(n_way=5,k_shot=10,inner_update_lr=0.4,num_inner_updates=1,meta_train=False, meta_train_k_shot=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohmGfgV-geFj"
      },
      "source": [
        "# models/ProtoNet\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "class ProtoNet(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, num_filters, latent_dim):\n",
        "    super(ProtoNet, self).__init__()\n",
        "    self.num_filters = num_filters\n",
        "    self.latent_dim = latent_dim\n",
        "    num_filter_list = self.num_filters + [latent_dim]\n",
        "    self.convs = []\n",
        "    for i, num_filter in enumerate(num_filter_list):\n",
        "      block_parts = [\n",
        "        layers.Conv2D(\n",
        "          filters=num_filter,\n",
        "          kernel_size=3,\n",
        "          padding='SAME',\n",
        "          activation='linear'),\n",
        "      ]\n",
        "\n",
        "      block_parts += [layers.BatchNormalization()]\n",
        "      block_parts += [layers.Activation('relu')]\n",
        "      block_parts += [layers.MaxPool2D()]\n",
        "      block = tf.keras.Sequential(block_parts, name='conv_block_%d' % i)\n",
        "      self.__setattr__(\"conv%d\" % i, block)\n",
        "      self.convs.append(block)\n",
        "    self.flatten = tf.keras.layers.Flatten()\n",
        "\n",
        "  def call(self, inp):\n",
        "    out = inp\n",
        "    for conv in self.convs:\n",
        "      out = conv(out)\n",
        "    out = self.flatten(out)\n",
        "    return out\n",
        "\n",
        "def ProtoLoss(x_latent, q_latent, labels_onehot, num_classes, num_support, num_queries):\n",
        "  \"\"\"\n",
        "    calculates the prototype network loss using the latent representation of x\n",
        "    and the latent representation of the query set\n",
        "    Args:\n",
        "      x_latent: latent representation of supports with shape [N*S, D], where D is the latent dimension\n",
        "      q_latent: latent representation of queries with shape [N*Q, D], where D is the latent dimension\n",
        "      labels_onehot: one-hot encodings of the labels of the queries with shape [N, Q, N]\n",
        "      num_classes: number of classes (N) for classification\n",
        "      num_support: number of examples (S) in the support set\n",
        "      num_queries: number of examples (Q) in the query set\n",
        "    Returns:\n",
        "      ce_loss: the cross entropy loss between the predicted labels and true labels\n",
        "      acc: the accuracy of classification on the queries\n",
        "  \"\"\"\n",
        "  #############################\n",
        "  #### YOUR CODE GOES HERE ####\n",
        "\n",
        "  # compute the prototypes\n",
        "  # compute the distance from the prototypes\n",
        "  # compute cross entropy loss\n",
        "  # note - additional steps are needed!\n",
        "  # return the cross-entropy loss and accuracy\n",
        "\n",
        "  #############################\n",
        "\n",
        "  # ------------------\n",
        "  # Compute Prototypes\n",
        "  # ------------------\n",
        "  x_latent_labels = labels_onehot[:,:,:num_support,:].squeeze()\n",
        "  q_latent_labels = labels_onehot[:,:,-1*num_queries:,:].squeeze()\n",
        "\n",
        "  # print(x_latent.shape)\n",
        "  latent_sets = []\n",
        "  for idx in range(x_latent.shape[0]//num_support):\n",
        "    # print(idx, idx*num_support, (idx+1)*num_support)\n",
        "    latent_sets.append(tf.reduce_mean(x_latent[idx*num_support:(idx+1)*num_support], axis = 0))\n",
        "    # print(x_latent[idx*num_support:(idx+1)*num_support].shape)\n",
        "    # print(latent_sets.shape)\n",
        "\n",
        "\n",
        "  # latent_sets = np.zeros((num_classes, x_latent.shape[1]))\n",
        "  # K = np.zeros(num_classes)\n",
        "  # for idx, latent in enumerate(x_latent):\n",
        "  #   curr_label = x_latent_labels[idx]\n",
        "  #   label_idx = int(np.where(curr_label==1)[0]) # Which index has the 1?\n",
        "  #   latent_sets[label_idx] += latent\n",
        "  #   K[label_idx]+=1\n",
        "  # latent_sets = np.transpose(np.transpose(latent_sets) / K)\n",
        "  # latent_sets = latent_sets + tf.random.uniform(shape=[1], maxval=0.001, dtype=tf.float32)\n",
        "\n",
        "  # print(\"[PROTOLOSS] latent_sets.shape=\", latent_sets.shape)\n",
        "\n",
        "  # Compute distances between prototypes and queries, convert to logits\n",
        "\n",
        "  # distances_old = np.zeros((q_latent.shape[0], num_classes))\n",
        "  # # print(type(q_latent))\n",
        "  # # correct_labels = np.zeros(q_latent.shape[0], dtype=np.int)\n",
        "  # # temp_q_labels = q_latent_labels.reshape(q_latent.shape[0], num_classes)\n",
        "  # for query_idx, query_val in enumerate(q_latent):\n",
        "  #   for support_idx, support_val in enumerate(latent_sets):\n",
        "  #     distances_old[query_idx, support_idx] = np.sqrt(np.dot((query_val-support_val),(query_val-support_val)))\n",
        "  #   # correct_labels[query_idx] = int(np.where(temp_q_labels[query_idx]==1)[0])\n",
        "  \n",
        "\n",
        "  delta = q_latent - latent_sets[0]\n",
        "  distances = tf.math.reduce_euclidean_norm(delta, 1, keepdims=True)\n",
        "\n",
        "  for support_idx in range(num_classes-1):\n",
        "    delta = q_latent - latent_sets[support_idx+1]\n",
        "    delta = tf.math.reduce_euclidean_norm(delta, 1, keepdims=True)\n",
        "    distances = tf.concat([distances, delta], 1)\n",
        "\n",
        "\n",
        "  correct_labels = np.zeros(q_latent.shape[0], dtype=np.int)\n",
        "  q_latent_labels_reshaped = q_latent_labels.reshape(q_latent.shape[0], num_classes)\n",
        "  for query_idx in range(q_latent.shape[0]):\n",
        "    correct_labels[query_idx] = int(np.where(q_latent_labels_reshaped[query_idx]==1)[0])\n",
        "\n",
        "  # Compute accuracies \n",
        "  decisions = np.argmin(distances, axis=1)\n",
        "  result = len(np.where(decisions-correct_labels == 0)[0])\n",
        "  acc = result/q_latent.shape[0]\n",
        "\n",
        "\n",
        "  loss_fn = partial(cross_entropy_loss, k_shot=1)\n",
        "  ce_loss = loss_fn(-1*distances, q_latent_labels_reshaped)\n",
        "\n",
        "  # # Compute cross entropy loss\n",
        "  # ce_loss = tf.reduce_sum(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=correct_labels.squeeze(), logits=-1*distances))\n",
        "\n",
        "  return ce_loss, acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_bOml4PhkSM"
      },
      "source": [
        "# run_ProtoNet\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import os\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def proto_net_train_step(model, optim, x, q, labels_ph):\n",
        "  num_classes, num_support, im_height, im_width, channels = x.shape\n",
        "  num_queries = q.shape[1]\n",
        "  x = tf.reshape(x, [-1, im_height, im_width, channels])\n",
        "  q = tf.reshape(q, [-1, im_height, im_width, channels])\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    x_latent = model(x)\n",
        "    q_latent = model(q)\n",
        "    ce_loss, acc = ProtoLoss(x_latent, q_latent, labels_ph, num_classes, num_support, num_queries)\n",
        "\n",
        "  gradients = tape.gradient(ce_loss, model.trainable_variables)\n",
        "  optim.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "  return ce_loss, acc\n",
        "\n",
        "def proto_net_eval(model, x, q, labels_ph):\n",
        "  num_classes, num_support, im_height, im_width, channels = x.shape\n",
        "  num_queries = q.shape[1]\n",
        "  x = tf.reshape(x, [-1, im_height, im_width, channels])\n",
        "  q = tf.reshape(q, [-1, im_height, im_width, channels])\n",
        "\n",
        "  x_latent = model(x)\n",
        "  q_latent = model(q)\n",
        "  ce_loss, acc = ProtoLoss(x_latent, q_latent, labels_ph, num_classes, num_support, num_queries)\n",
        "\n",
        "  return ce_loss, acc \n",
        "\n",
        "def run_protonet(data_path='./omniglot_resized', n_way=20, k_shot=1, n_query=5, n_meta_test_way=20, k_meta_test_shot=5, n_meta_test_query=5):\n",
        "  n_epochs = 20\n",
        "  n_episodes = 100\n",
        "\n",
        "  im_width, im_height, channels = 28, 28, 1\n",
        "  num_filters = 32\n",
        "  latent_dim = 16\n",
        "  num_conv_layers = 3\n",
        "  n_meta_test_episodes = 1000\n",
        "\n",
        "  model = ProtoNet([num_filters]*num_conv_layers, latent_dim)\n",
        "  optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "  meta_val_accuracies_log = []\n",
        "  meta_val_iteration_key = []\n",
        "\n",
        "    # call DataGenerator with k_shot+n_query samples per class\n",
        "  data_generator = DataGenerator(n_way, k_shot+n_query, n_meta_test_way, k_meta_test_shot+n_meta_test_query)\n",
        "  for ep in range(n_epochs):\n",
        "    for epi in range(n_episodes):\n",
        "      #############################\n",
        "      #### YOUR CODE GOES HERE ####\n",
        "\n",
        "      # sample a batch of training data and partition into\n",
        "      # support and query sets\n",
        "\n",
        "      # ---------------------------\n",
        "      # EP: Start Implementation\n",
        "      inputs, labels = data_generator.sample_batch('meta_train', 1, shuffle=False)\n",
        "      # print(\"labels shape: \", labels.shape)\n",
        "      # print(labels)\n",
        "\n",
        "      # EP: Support\n",
        "      support = tf.reshape(inputs[:,:,:k_shot,:], [inputs.shape[1], k_shot, im_width, im_height, channels])\n",
        "      # label_support = labels[:,:,:k_shot,:] \n",
        "\n",
        "      # EP: Query\n",
        "      query = tf.reshape(inputs[:,:,-1*n_query:,:], [inputs.shape[1], n_query, im_width, im_height, channels])\n",
        "      # label_query = labels[:,:,-1*n_query:,:]\n",
        "      # ---------------------------\n",
        "\n",
        "      #############################\n",
        "      ls, ac = proto_net_train_step(model, optimizer, x=support, q=query, labels_ph=labels)\n",
        "      if (epi+1) % 50 == 0:\n",
        "        #############################\n",
        "        #### YOUR CODE GOES HERE ####\n",
        "\n",
        "        # sample a batch of validation data and partition into\n",
        "        # support and query sets\n",
        "\n",
        "        # ---------------------------\n",
        "        # EP: Start Implementation\n",
        "        inputs, labels = data_generator.sample_batch('meta_val', 1, shuffle=False)\n",
        "\n",
        "        # EP: Support\n",
        "        support = tf.reshape(inputs[:,:,:k_shot,:], [inputs.shape[1], k_shot, im_width, im_height, channels])\n",
        "        # label_support = labels[:,:,:k_shot,:] \n",
        "\n",
        "        # EP: Query\n",
        "        query = tf.reshape(inputs[:,:,-1*n_query:,:], [inputs.shape[1], n_query, im_width, im_height, channels])\n",
        "        # label_query = labels[:,:,-1*n_query:,:]\n",
        "        # ---------------------------\n",
        "\n",
        "        #############################\n",
        "        val_ls, val_ac = proto_net_eval(model, x=support, q=query, labels_ph=labels)\n",
        "        print('[epoch {}/{}, episode {}/{}] => meta-training loss: {:.5f}, meta-training acc: {:.5f}, meta-val loss: {:.5f}, meta-val acc: {:.5f}'.format(ep+1,\n",
        "                                                                    n_epochs,\n",
        "                                                                    epi+1,\n",
        "                                                                    n_episodes,\n",
        "                                                                    ls,\n",
        "                                                                    ac,\n",
        "                                                                    val_ls,\n",
        "                                                                    val_ac))\n",
        "\n",
        "        meta_val_accuracies_log.append(val_ac)\n",
        "        meta_val_iteration_key.append(ep*100 + epi)\n",
        "\n",
        "  # Plot Results\n",
        "  plt.figure(figsize=(12,8))\n",
        "  plt.plot(meta_val_iteration_key, meta_val_accuracies_log, label=\"val_acc\")\n",
        "  plt.title(\"Prototypical Network Meta-val results\")\n",
        "  plt.xlabel(\"Iterations\")\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.ylim([0,1])\n",
        "  plt.grid()\n",
        "  plt.legend()\n",
        "      \n",
        "  print('Testing...')\n",
        "  meta_test_accuracies = []\n",
        "  for epi in range(n_meta_test_episodes):\n",
        "    #############################\n",
        "    #### YOUR CODE GOES HERE ####\n",
        "\n",
        "    # sample a batch of test data and partition into\n",
        "    # support and query sets\n",
        "\n",
        "    # ---------------------------\n",
        "    # EP: Start Implementation\n",
        "    inputs, labels = data_generator.sample_batch('meta_test', 1, shuffle=False)\n",
        "\n",
        "    # EP: Support\n",
        "    support = tf.reshape(inputs[:,:,:k_shot,:], [inputs.shape[1], k_shot, im_width, im_height, channels])\n",
        "    # label_support = labels[:,:,:k_shot,:] \n",
        "\n",
        "    # EP: Query\n",
        "    query = tf.reshape(inputs[:,:,-1*n_query:,:], [inputs.shape[1], n_query, im_width, im_height, channels])\n",
        "    # label_query = labels[:,:,-1*n_query:,:]\n",
        "    # ---------------------------\n",
        "\n",
        "    #############################\n",
        "    ls, ac = proto_net_eval(model, x=support, q=query, labels_ph=labels)\n",
        "    meta_test_accuracies.append(ac)\n",
        "    if (epi+1) % 50 == 0:\n",
        "      print('[meta-test episode {}/{}] => loss: {:.5f}, acc: {:.5f}'.format(epi+1, n_meta_test_episodes, ls, ac))\n",
        "  avg_acc = np.mean(meta_test_accuracies)\n",
        "  stds = np.std(meta_test_accuracies)\n",
        "  print('Average Meta-Test Accuracy: {:.5f}, Meta-Test Accuracy Std: {:.5f}'.format(avg_acc, stds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6Tv12fbTQqJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bec3d70d-a5e4-444c-b63a-7420461638fc"
      },
      "source": [
        "run_protonet('./omniglot_resized/', n_way=5, k_shot=1, n_query=5, n_meta_test_way=5, k_meta_test_shot=6, n_meta_test_query=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[epoch 1/20, episode 50/100] => meta-training loss: 1.03733, meta-training acc: 0.56000, meta-val loss: 0.51639, meta-val acc: 0.88000\n",
            "[epoch 1/20, episode 100/100] => meta-training loss: 0.27666, meta-training acc: 0.96000, meta-val loss: 0.39981, meta-val acc: 0.84000\n",
            "[epoch 2/20, episode 50/100] => meta-training loss: 0.40146, meta-training acc: 0.84000, meta-val loss: 0.35827, meta-val acc: 0.88000\n",
            "[epoch 2/20, episode 100/100] => meta-training loss: 0.32942, meta-training acc: 0.84000, meta-val loss: 0.35543, meta-val acc: 0.88000\n",
            "[epoch 3/20, episode 50/100] => meta-training loss: 0.63637, meta-training acc: 0.80000, meta-val loss: 0.53028, meta-val acc: 0.80000\n",
            "[epoch 3/20, episode 100/100] => meta-training loss: 0.34434, meta-training acc: 0.88000, meta-val loss: 0.34937, meta-val acc: 0.84000\n",
            "[epoch 4/20, episode 50/100] => meta-training loss: 0.50130, meta-training acc: 0.84000, meta-val loss: 1.09815, meta-val acc: 0.60000\n",
            "[epoch 4/20, episode 100/100] => meta-training loss: 0.35081, meta-training acc: 0.88000, meta-val loss: 0.59998, meta-val acc: 0.72000\n",
            "[epoch 5/20, episode 50/100] => meta-training loss: 0.44874, meta-training acc: 0.76000, meta-val loss: 0.60810, meta-val acc: 0.72000\n",
            "[epoch 5/20, episode 100/100] => meta-training loss: 0.40672, meta-training acc: 0.80000, meta-val loss: 0.12443, meta-val acc: 0.96000\n",
            "[epoch 6/20, episode 50/100] => meta-training loss: 0.41389, meta-training acc: 0.80000, meta-val loss: 1.05859, meta-val acc: 0.76000\n",
            "[epoch 6/20, episode 100/100] => meta-training loss: 0.44880, meta-training acc: 0.80000, meta-val loss: 0.54293, meta-val acc: 0.80000\n",
            "[epoch 7/20, episode 50/100] => meta-training loss: 0.86250, meta-training acc: 0.64000, meta-val loss: 0.37696, meta-val acc: 0.88000\n",
            "[epoch 7/20, episode 100/100] => meta-training loss: 0.91012, meta-training acc: 0.72000, meta-val loss: 0.39351, meta-val acc: 0.88000\n",
            "[epoch 8/20, episode 50/100] => meta-training loss: 0.14460, meta-training acc: 1.00000, meta-val loss: 0.17892, meta-val acc: 0.92000\n",
            "[epoch 8/20, episode 100/100] => meta-training loss: 0.70619, meta-training acc: 0.76000, meta-val loss: 0.09995, meta-val acc: 0.96000\n",
            "[epoch 9/20, episode 50/100] => meta-training loss: 0.42107, meta-training acc: 0.80000, meta-val loss: 0.09990, meta-val acc: 0.96000\n",
            "[epoch 9/20, episode 100/100] => meta-training loss: 0.23429, meta-training acc: 0.92000, meta-val loss: 0.17020, meta-val acc: 0.92000\n",
            "[epoch 10/20, episode 50/100] => meta-training loss: 0.35102, meta-training acc: 0.88000, meta-val loss: 0.30673, meta-val acc: 0.88000\n",
            "[epoch 10/20, episode 100/100] => meta-training loss: 0.50740, meta-training acc: 0.84000, meta-val loss: 0.24603, meta-val acc: 0.92000\n",
            "[epoch 11/20, episode 50/100] => meta-training loss: 0.26317, meta-training acc: 0.88000, meta-val loss: 0.54146, meta-val acc: 0.80000\n",
            "[epoch 11/20, episode 100/100] => meta-training loss: 0.25535, meta-training acc: 0.84000, meta-val loss: 0.39614, meta-val acc: 0.88000\n",
            "[epoch 12/20, episode 50/100] => meta-training loss: 0.20897, meta-training acc: 0.92000, meta-val loss: 0.35453, meta-val acc: 0.88000\n",
            "[epoch 12/20, episode 100/100] => meta-training loss: 0.10255, meta-training acc: 0.96000, meta-val loss: 0.14348, meta-val acc: 0.96000\n",
            "[epoch 13/20, episode 50/100] => meta-training loss: 0.31314, meta-training acc: 0.84000, meta-val loss: 0.31933, meta-val acc: 0.88000\n",
            "[epoch 13/20, episode 100/100] => meta-training loss: 0.13344, meta-training acc: 0.96000, meta-val loss: 0.39720, meta-val acc: 0.96000\n",
            "[epoch 14/20, episode 50/100] => meta-training loss: 0.27438, meta-training acc: 0.84000, meta-val loss: 0.06600, meta-val acc: 0.96000\n",
            "[epoch 14/20, episode 100/100] => meta-training loss: 0.05989, meta-training acc: 1.00000, meta-val loss: 0.06331, meta-val acc: 1.00000\n",
            "[epoch 15/20, episode 50/100] => meta-training loss: 0.07208, meta-training acc: 1.00000, meta-val loss: 0.24445, meta-val acc: 0.92000\n",
            "[epoch 15/20, episode 100/100] => meta-training loss: 0.19582, meta-training acc: 0.92000, meta-val loss: 0.11064, meta-val acc: 0.96000\n",
            "[epoch 16/20, episode 50/100] => meta-training loss: 0.26408, meta-training acc: 0.92000, meta-val loss: 0.46427, meta-val acc: 0.72000\n",
            "[epoch 16/20, episode 100/100] => meta-training loss: 0.05027, meta-training acc: 1.00000, meta-val loss: 0.11870, meta-val acc: 0.96000\n",
            "[epoch 17/20, episode 50/100] => meta-training loss: 0.01683, meta-training acc: 1.00000, meta-val loss: 0.42223, meta-val acc: 0.84000\n",
            "[epoch 17/20, episode 100/100] => meta-training loss: 0.25769, meta-training acc: 0.88000, meta-val loss: 0.08904, meta-val acc: 0.96000\n",
            "[epoch 18/20, episode 50/100] => meta-training loss: 0.31270, meta-training acc: 0.92000, meta-val loss: 0.05980, meta-val acc: 1.00000\n",
            "[epoch 18/20, episode 100/100] => meta-training loss: 0.05140, meta-training acc: 1.00000, meta-val loss: 0.09476, meta-val acc: 1.00000\n",
            "[epoch 19/20, episode 50/100] => meta-training loss: 0.43967, meta-training acc: 0.80000, meta-val loss: 0.21127, meta-val acc: 0.88000\n",
            "[epoch 19/20, episode 100/100] => meta-training loss: 0.38589, meta-training acc: 0.88000, meta-val loss: 0.28010, meta-val acc: 0.80000\n",
            "[epoch 20/20, episode 50/100] => meta-training loss: 0.35916, meta-training acc: 0.84000, meta-val loss: 0.33621, meta-val acc: 0.88000\n",
            "[epoch 20/20, episode 100/100] => meta-training loss: 0.19029, meta-training acc: 0.92000, meta-val loss: 2.56938, meta-val acc: 0.68000\n",
            "Testing...\n",
            "[meta-test episode 50/1000] => loss: 0.09675, acc: 1.00000\n",
            "[meta-test episode 100/1000] => loss: 0.25799, acc: 0.96000\n",
            "[meta-test episode 150/1000] => loss: 0.04822, acc: 1.00000\n",
            "[meta-test episode 200/1000] => loss: 0.47760, acc: 0.88000\n",
            "[meta-test episode 250/1000] => loss: 0.44438, acc: 0.84000\n",
            "[meta-test episode 300/1000] => loss: 0.11189, acc: 1.00000\n",
            "[meta-test episode 350/1000] => loss: 0.32790, acc: 0.88000\n",
            "[meta-test episode 400/1000] => loss: 0.24796, acc: 0.88000\n",
            "[meta-test episode 450/1000] => loss: 0.21618, acc: 0.92000\n",
            "[meta-test episode 500/1000] => loss: 0.20455, acc: 1.00000\n",
            "[meta-test episode 550/1000] => loss: 0.25284, acc: 0.92000\n",
            "[meta-test episode 600/1000] => loss: 0.35471, acc: 0.88000\n",
            "[meta-test episode 650/1000] => loss: 0.26632, acc: 0.92000\n",
            "[meta-test episode 700/1000] => loss: 0.17892, acc: 0.96000\n",
            "[meta-test episode 750/1000] => loss: 0.19288, acc: 0.88000\n",
            "[meta-test episode 800/1000] => loss: 0.19067, acc: 0.96000\n",
            "[meta-test episode 850/1000] => loss: 0.18126, acc: 0.96000\n",
            "[meta-test episode 900/1000] => loss: 0.03658, acc: 1.00000\n",
            "[meta-test episode 950/1000] => loss: 0.07513, acc: 0.96000\n",
            "[meta-test episode 1000/1000] => loss: 0.44653, acc: 0.80000\n",
            "Average Meta-Test Accuracy: 0.89856, Meta-Test Accuracy Std: 0.09004\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}